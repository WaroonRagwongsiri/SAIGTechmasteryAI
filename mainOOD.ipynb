{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>which python<p>\n",
    "<p>source .venv/bin/activate<p>\n",
    "<p>jupyter notebook --no-browser --ip=0.0.0.0<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "print(\"Loading dataset...\")\n",
    "train_df = pd.read_csv('data/Train.csv')\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "meta_df = pd.read_csv('data/Meta.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Meta data shape: {meta_df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test_df.head())\n",
    "\n",
    "print(\"\\nMeta data sample:\")\n",
    "print(meta_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique classes in training data\n",
    "unique_classes = sorted(train_df['ClassId'].unique())\n",
    "print(f\"\\nUnique classes in training: {unique_classes}\")\n",
    "print(f\"Number of classes: {len(unique_classes)}\")\n",
    "\n",
    "# Class distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Class distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "class_counts = train_df['ClassId'].value_counts().sort_index()\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Image dimensions analysis\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(train_df['Width'], train_df['Height'], alpha=0.6)\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Image Dimensions Distribution')\n",
    "\n",
    "# ROI (Region of Interest) analysis\n",
    "plt.subplot(1, 3, 3)\n",
    "roi_width = train_df['Roi.X2'] - train_df['Roi.X1']\n",
    "roi_height = train_df['Roi.Y2'] - train_df['Roi.Y1']\n",
    "plt.scatter(roi_width, roi_height, alpha=0.6)\n",
    "plt.xlabel('ROI Width')\n",
    "plt.ylabel('ROI Height')\n",
    "plt.title('ROI Dimensions Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtStyleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for Art Style Classification\n",
    "    \n",
    "    This class handles:\n",
    "    - Loading images from file paths\n",
    "    - Applying ROI cropping if specified\n",
    "    - Applying transformations (augmentation)\n",
    "    - Converting to tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, root_dir, transform=None, use_roi=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: pandas DataFrame with image paths and labels\n",
    "            root_dir: Root directory containing images\n",
    "            transform: Optional transform to be applied on images\n",
    "            use_roi: Whether to use ROI cropping\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.use_roi = use_roi\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Get image path and label\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row['Path'])\n",
    "        label = row['ClassId']\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not load image: {img_path}\")\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Apply ROI cropping if specified\n",
    "            if self.use_roi and all(col in row for col in ['Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2']):\n",
    "                x1, y1, x2, y2 = int(row['Roi.X1']), int(row['Roi.Y1']), int(row['Roi.X2']), int(row['Roi.Y2'])\n",
    "                image = image[y1:y2, x1:x2]\n",
    "            \n",
    "            # Convert to PIL Image for transforms\n",
    "            image = Image.fromarray(image)\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a black image if there's an error\n",
    "            if self.transform:\n",
    "                image = self.transform(Image.new('RGB', (224, 224), (0, 0, 0)))\n",
    "            else:\n",
    "                image = torch.zeros(3, 224, 224)\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Data Transforms and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training (with augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transforms for validation/test (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined:\")\n",
    "print(\"- Training: Resize, Rotation, Flip, ColorJitter, Normalize\")\n",
    "print(\"- Validation: Resize, Normalize only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6: Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training data to only include classes 0-41 (42 classes total)\n",
    "# This leaves class 42 as OOD (Out-of-Distribution)\n",
    "train_df_filtered = train_df[train_df['ClassId'] <= 41].copy()\n",
    "\n",
    "print(f\"Original training samples: {len(train_df)}\")\n",
    "print(f\"Filtered training samples (classes 0-41): {len(train_df_filtered)}\")\n",
    "print(f\"Class 42 samples excluded: {len(train_df[train_df['ClassId'] == 42])}\")\n",
    "\n",
    "# Split filtered training data into train and validation sets\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df_filtered,  # Use filtered dataframe instead of train_df\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train_df_filtered['ClassId']  # Use filtered dataframe for stratification\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ArtStyleDataset(train_data, 'data', transform=train_transforms, use_roi=True)\n",
    "val_dataset = ArtStyleDataset(val_data, 'data', transform=val_transforms, use_roi=True)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7: Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, title=None):\n",
    "    \"\"\"Display a tensor as an image\"\"\"\n",
    "    # Denormalize the image\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    image = tensor.clone().detach()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def visualize_batch(data_loader, num_samples=8):\n",
    "    \"\"\"Visualize a batch of images\"\"\"\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        imshow(images[i], title=f'Class {labels[i].item()}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training samples\n",
    "print(\"Sample training images:\")\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtStyleClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN model for art style classification using transfer learning\n",
    "    \n",
    "    Architecture:\n",
    "    - Pre-trained ResNet50 as backbone\n",
    "    - Custom classifier head\n",
    "    - Dropout for regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ArtStyleClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features from the last layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace the final layer with custom classifier\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Alternative: EfficientNet model\n",
    "class EfficientNetClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Alternative model using EfficientNet\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained EfficientNet\n",
    "        self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        # Replace classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Update unique_classes to reflect only the classes we're training on\n",
    "unique_classes = sorted(train_df_filtered['ClassId'].unique())\n",
    "print(f\"\\nUnique classes in training: {unique_classes}\")\n",
    "print(f\"Number of classes: {len(unique_classes)}\")\n",
    "\n",
    "# Create model\n",
    "num_classes = len(unique_classes)  # This will be 42 instead of 43\n",
    "model = ArtStyleClassifier(num_classes, pretrained=True)\n",
    "# model = EfficientNetClassifier(num_classes, pretrained=True)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model architecture\n",
    "print(f\"Model created with {num_classes} classes\")\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 9: Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training setup:\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"Scheduler: StepLR (step_size=10, gamma=0.1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        Average loss and accuracy for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        Average loss, accuracy, and F1 score for the epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='Validation')\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions for F1 score calculation\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    return epoch_loss, epoch_acc, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 11: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    \"\"\"\n",
    "    Complete training loop with validation\n",
    "    \n",
    "    Returns:\n",
    "        Training history dictionary\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1_macro': [],\n",
    "        'val_f1_weighted': []\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_f1_macro, val_f1_weighted = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if val_f1_macro > best_f1:\n",
    "            best_f1 = val_f1_macro\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best F1 score: {best_f1:.4f}\")\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1_macro'].append(val_f1_macro)\n",
    "        history['val_f1_weighted'].append(val_f1_weighted)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Val F1 (Macro): {val_f1_macro:.4f}, Val F1 (Weighted): {val_f1_weighted:.4f}')\n",
    "        print(f'Current LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch > 10 and val_f1_macro < max(history['val_f1_macro'][-10:]) - 0.01:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Best model loaded with F1 score: {best_f1:.4f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 12: Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # F1 Score plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_f1_macro'], label='F1 Macro')\n",
    "    plt.plot(history['val_f1_weighted'], label='F1 Weighted')\n",
    "    plt.title('F1 Scores')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 13: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Evaluating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Final F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"Final F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return f1_macro, f1_weighted, all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "f1_macro, f1_weighted, val_probabilities = evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 14: Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model, test_df, root_dir, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    Make predictions on test data\n",
    "    \"\"\"\n",
    "    # Create test dataset\n",
    "    test_dataset = ArtStyleDataset(test_df, root_dir, transform=val_transforms, use_roi=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(test_loader, desc='Predicting'):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions, test_probabilities = predict_test_data(model, test_df, 'data', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 15: Handle Unknown Class (11th Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_unknown_class(predictions, probabilities, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Detect potential unknown class based on prediction confidence\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted class labels\n",
    "        probabilities: Prediction probabilities for each class\n",
    "        threshold: Confidence threshold below which we classify as unknown\n",
    "    \n",
    "    Returns:\n",
    "        Modified predictions with unknown class\n",
    "    \"\"\"\n",
    "    # Get maximum probability for each prediction\n",
    "    max_probabilities = np.max(probabilities, axis=1)\n",
    "    \n",
    "    # Create a copy of predictions\n",
    "    modified_predictions = predictions.copy()\n",
    "    \n",
    "    # Mark low-confidence predictions as unknown class (assuming class 10 is unknown)\n",
    "    unknown_mask = max_probabilities < threshold\n",
    "    modified_predictions[unknown_mask] = 10  # Unknown class\n",
    "    \n",
    "    print(f\"Detected {np.sum(unknown_mask)} potential unknown class samples\")\n",
    "    print(f\"Percentage of unknown samples: {np.sum(unknown_mask)/len(predictions)*100:.2f}%\")\n",
    "    \n",
    "    return modified_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect unknown class samples\n",
    "final_predictions = detect_unknown_class(test_predictions, test_probabilities, threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 16: Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(test_df, predictions, output_file='submission.csv'):\n",
    "    \"\"\"\n",
    "    Create submission file in required format\n",
    "    \"\"\"\n",
    "    submission_df = test_df.copy()\n",
    "    submission_df['PredictedClassId'] = predictions\n",
    "    \n",
    "    # Save submission file\n",
    "    submission_df[['Path', 'PredictedClassId']].to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Submission file saved as {output_file}\")\n",
    "    \n",
    "    # Display prediction distribution\n",
    "    pred_counts = pd.Series(predictions).value_counts().sort_index()\n",
    "    print(\"\\nPrediction distribution:\")\n",
    "    print(pred_counts)\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = create_submission(test_df, final_predictions, output_file=\"submissionOOD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 17: Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'num_classes': num_classes,\n",
    "    'f1_score': f1_macro,\n",
    "    'history': history\n",
    "}, 'art_style_classifierOOD.pth')\n",
    "\n",
    "print(\"Model saved as 'art_style_classifierOOD.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model\n",
    "def load_model(model_path, num_classes):\n",
    "    \"\"\"\n",
    "    Load a saved model\n",
    "    \"\"\"\n",
    "    model = ArtStyleClassifier(num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Best F1 score: {checkpoint['f1_score']:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example of loading the model\n",
    "# loaded_model = load_model('art_style_classifier.pth', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 18: Advanced Features (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ensemble example\n",
    "def create_ensemble_predictions(models, test_loader, device):\n",
    "    \"\"\"\n",
    "    Create ensemble predictions from multiple models\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                model_predictions.append(probabilities.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(np.concatenate(model_predictions))\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_predictions = np.mean(all_predictions, axis=0)\n",
    "    final_predictions = np.argmax(ensemble_predictions, axis=1)\n",
    "    \n",
    "    return final_predictions, ensemble_predictions\n",
    "\n",
    "# Gradient-weighted Class Activation Mapping (Grad-CAM)\n",
    "def generate_gradcam(model, image, class_idx, target_layer):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for model interpretability\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    features = []\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(output)\n",
    "    \n",
    "    handle = target_layer.register_forward_hook(hook_fn)\n",
    "    \n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = model(image)\n",
    "    \n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    output[0, class_idx].backward()\n",
    "    \n",
    "    # Get gradients and features\n",
    "    gradients = target_layer.weight.grad\n",
    "    activations = features[0]\n",
    "    \n",
    "    # Generate heatmap\n",
    "    weights = torch.mean(gradients, dim=(2, 3))\n",
    "    heatmap = torch.zeros(activations.shape[2:]).to(device)\n",
    "    \n",
    "    for i in range(weights.shape[1]):\n",
    "        heatmap += weights[0, i] * activations[0, i]\n",
    "    \n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap = heatmap / torch.max(heatmap)\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    return heatmap.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 19: Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated load_model function to return history\n",
    "def load_model_with_history(model_path, num_classes):\n",
    "    \"\"\"\n",
    "    Load a saved model along with its training history\n",
    "    \"\"\"\n",
    "    model = ArtStyleClassifier(num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    # Extract history if available\n",
    "    history = checkpoint.get('history', None)\n",
    "    f1_score = checkpoint.get('f1_score', 0.0)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Best F1 score: {f1_score:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Option to load model instead of training\n",
    "USE_SAVED_MODEL = True  # Set to True if you want to load a saved model\n",
    "\n",
    "if USE_SAVED_MODEL:\n",
    "    # Load the saved model\n",
    "    loaded_model, history = load_model_with_history('art_style_classifierOOD.pth', num_classes)\n",
    "    model = loaded_model\n",
    "    \n",
    "    # If no history available, skip visualization or create dummy\n",
    "    if history is None:\n",
    "        print(\"No training history available - skipping training plots\")\n",
    "        # You can either skip plot_training_history() or create dummy data\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'val_f1_macro': [],\n",
    "            'val_f1_weighted': []\n",
    "        }\n",
    "else:\n",
    "    # Use the freshly trained model (existing code continues)\n",
    "    history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "    \n",
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions, test_probabilities = predict_test_data(model, test_df, 'data', device)\n",
    "# Continue with evaluation\n",
    "f1_macro, f1_weighted, val_probabilities = evaluate_model(model, val_loader, device)\n",
    "# Detect unknown class samples\n",
    "final_predictions = detect_unknown_class(test_predictions, test_probabilities, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"Final F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"Number of test predictions: {len(final_predictions)}\")\n",
    "print(f\"Model saved: art_style_classifier.pth\")\n",
    "print(f\"Submission file: submission.csv\")\n",
    "print(f\"Device used: {device}\")\n",
    "print(f\"Total training time: {len(history['train_loss'])} epochs\")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"- Base model: ResNet50 (pre-trained)\")\n",
    "print(f\"- Number of classes: {num_classes}\")\n",
    "print(f\"- Total parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\nNext steps to improve performance:\")\n",
    "print(\"1. Try different architectures (EfficientNet, Vision Transformer)\")\n",
    "print(\"2. Experiment with different data augmentation techniques\")\n",
    "print(\"3. Implement test-time augmentation (TTA)\")\n",
    "print(\"4. Use model ensembling\")\n",
    "print(\"5. Fine-tune hyperparameters\")\n",
    "print(\"6. Implement advanced loss functions (Focal Loss, Label Smoothing)\")\n",
    "print(\"7. Use cross-validation for more robust evaluation\")\n",
    "print(\"8. Analyze model predictions with Grad-CAM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
