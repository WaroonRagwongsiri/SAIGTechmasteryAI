{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>which python<p>\n",
    "<p>source .venv/bin/activate<p>\n",
    "<p>jupyter notebook --no-browser --ip=0.0.0.0<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import kagglehub\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the dataset\n",
    "print(\"Downloading dataset...\")\n",
    "path = kagglehub.dataset_download(\"kritikseth/fruit-and-vegetable-image-recognition\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Set up directory paths\n",
    "train_dir = os.path.join(path, \"train\")\n",
    "test_dir = os.path.join(path, \"test\") \n",
    "val_dir = os.path.join(path, \"validation\")\n",
    "\n",
    "# Get categories from training directory\n",
    "categories = os.listdir(train_dir)\n",
    "print(f\"There are {len(categories)} types of fruits and vegetables:\\n{categories}\")\n",
    "\n",
    "def count_images_per_category(directory):\n",
    "    total_images = 0\n",
    "    category_counts = {}    \n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            image_files = [image_name for image_name in os.listdir(category_path)]\n",
    "            len_category = len(image_files)\n",
    "            category_counts[category] = len_category\n",
    "            total_images += len_category\n",
    "    return total_images, category_counts\n",
    "\n",
    "# Get number of images found\n",
    "train_total, train_cat_counts = count_images_per_category(train_dir)\n",
    "val_total, val_cat_counts = count_images_per_category(val_dir)\n",
    "test_total, test_cat_counts = count_images_per_category(test_dir)\n",
    "\n",
    "print(f\"\\nTrain set: {train_total} images\")\n",
    "for cat, count in train_cat_counts.items():\n",
    "    print(f\" - {cat}: {count}\")\n",
    "\n",
    "print(f\"\\nValidation set: {val_total} images\")\n",
    "for cat, count in val_cat_counts.items():\n",
    "    print(f\" - {cat}: {count}\")\n",
    "\n",
    "print(f\"\\nTest set: {test_total} images\")\n",
    "for cat, count in test_cat_counts.items():\n",
    "    print(f\" - {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = sorted(os.listdir(train_dir))  # Already present\n",
    "in_distribution_classes = all_categories[:35]\n",
    "ood_class = all_categories[35]\n",
    "\n",
    "print(\"Train/Validation on:\", in_distribution_classes)\n",
    "print(\"Use as OOD:\", ood_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check unique classes in training data\n",
    "# unique_classes = sorted(train_df['ClassId'].unique())\n",
    "# print(f\"\\nUnique classes in training: {unique_classes}\")\n",
    "# print(f\"Number of classes: {len(unique_classes)}\")\n",
    "\n",
    "# # Class distribution analysis\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# # Class distribution\n",
    "# plt.subplot(1, 3, 1)\n",
    "# class_counts = train_df['ClassId'].value_counts().sort_index()\n",
    "# plt.bar(class_counts.index, class_counts.values)\n",
    "# plt.title('Class Distribution in Training Data')\n",
    "# plt.xlabel('Class ID')\n",
    "# plt.ylabel('Number of Images')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # Image dimensions analysis\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.scatter(train_df['Width'], train_df['Height'], alpha=0.6)\n",
    "# plt.xlabel('Width')\n",
    "# plt.ylabel('Height')\n",
    "# plt.title('Image Dimensions Distribution')\n",
    "\n",
    "# # ROI (Region of Interest) analysis\n",
    "# plt.subplot(1, 3, 3)\n",
    "# roi_width = train_df['Roi.X2'] - train_df['Roi.X1']\n",
    "# roi_height = train_df['Roi.Y2'] - train_df['Roi.Y1']\n",
    "# plt.scatter(roi_width, roi_height, alpha=0.6)\n",
    "# plt.xlabel('ROI Width')\n",
    "# plt.ylabel('ROI Height')\n",
    "# plt.title('ROI Dimensions Distribution')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitVegetableDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for Fruit and Vegetable Classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Directory containing category subdirectories\n",
    "            transform: Optional transform to be applied on images\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.categories = sorted(os.listdir(root_dir))\n",
    "        self.category_to_idx = {cat: idx for idx, cat in enumerate(self.categories)}\n",
    "        \n",
    "        # Build file list\n",
    "        self.samples = []\n",
    "        for category in self.categories:\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                for image_name in os.listdir(category_path):\n",
    "                    if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((\n",
    "                            os.path.join(category_path, image_name),\n",
    "                            self.category_to_idx[category]\n",
    "                        ))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not load image: {img_path}\")\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert to PIL Image for transforms\n",
    "            image = Image.fromarray(image)\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a black image if there's an error\n",
    "            if self.transform:\n",
    "                image = self.transform(Image.new('RGB', (224, 224), (0, 0, 0)))\n",
    "            else:\n",
    "                image = torch.zeros(3, 224, 224)\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, allowed_classes, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(allowed_classes)}\n",
    "\n",
    "        for cls in allowed_classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                self.image_paths.append(os.path.join(cls_path, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Data Transforms and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training (with augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transforms for validation/test (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined:\")\n",
    "print(\"- Training: Resize, Rotation, Flip, ColorJitter, Normalize\")\n",
    "print(\"- Validation: Resize, Normalize only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6: Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomImageDataset(train_dir, in_distribution_classes, transform=train_transforms)\n",
    "val_dataset = CustomImageDataset(val_dir, in_distribution_classes, transform=val_transforms)\n",
    "test_dataset = CustomImageDataset(test_dir, in_distribution_classes, transform=val_transforms)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7: Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, title=None):\n",
    "    \"\"\"Display a tensor as an image\"\"\"\n",
    "    # Denormalize the image\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    image = tensor.clone().detach()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def visualize_batch(data_loader, num_samples=8):\n",
    "    \"\"\"Visualize a batch of images\"\"\"\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        imshow(images[i], title=f'Class {labels[i].item()}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training samples\n",
    "print(\"Sample training images:\")\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOD dataset using class 36 only\n",
    "class OODImageDataset(Dataset):\n",
    "    def __init__(self, class_dir, transform=None):\n",
    "        self.image_paths = [os.path.join(class_dir, f) for f in os.listdir(class_dir)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_dataset = OODImageDataset(os.path.join(test_dir, ood_class), transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtStyleClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN model for art style classification using transfer learning\n",
    "    \n",
    "    Architecture:\n",
    "    - Pre-trained ResNet50 as backbone\n",
    "    - Custom classifier head\n",
    "    - Dropout for regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ArtStyleClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features from the last layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace the final layer with custom classifier\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Alternative: EfficientNet model\n",
    "class EfficientNetClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Alternative model using EfficientNet\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained EfficientNet\n",
    "        self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        \n",
    "        # Replace classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Update number of classes based on the dataset\n",
    "num_classes = len(in_distribution_classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Create model\n",
    "# model = ArtStyleClassifier(num_classes, pretrained=True)\n",
    "model = EfficientNetClassifier(num_classes, pretrained=True)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model info\n",
    "print(f\"Model created with {num_classes} classes\")\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 9: Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training setup:\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"Scheduler: StepLR (step_size=10, gamma=0.1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        Average loss and accuracy for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        Average loss, accuracy, and F1 score for the epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='Validation')\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions for F1 score calculation\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    return epoch_loss, epoch_acc, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 11: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    \"\"\"\n",
    "    Complete training loop with validation\n",
    "    \n",
    "    Returns:\n",
    "        Training history dictionary\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1_macro': [],\n",
    "        'val_f1_weighted': []\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_f1_macro, val_f1_weighted = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best model\n",
    "        if val_f1_macro > best_f1:\n",
    "            best_f1 = val_f1_macro\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best F1 score: {best_f1:.4f}\")\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1_macro'].append(val_f1_macro)\n",
    "        history['val_f1_weighted'].append(val_f1_weighted)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Val F1 (Macro): {val_f1_macro:.4f}, Val F1 (Weighted): {val_f1_weighted:.4f}')\n",
    "        print(f'Current LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch > 10 and val_f1_macro < max(history['val_f1_macro'][-10:]) - 0.01:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Best model loaded with F1 score: {best_f1:.4f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 12: Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # F1 Score plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_f1_macro'], label='F1 Macro')\n",
    "    plt.plot(history['val_f1_weighted'], label='F1 Weighted')\n",
    "    plt.title('F1 Scores')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 13: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Evaluating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Final F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"Final F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return f1_macro, f1_weighted, all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "f1_macro, f1_weighted, val_probabilities = evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 14: Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Make predictions on test data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(test_loader, desc='Predicting'):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions, test_probabilities = predict_test_data(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 15: Handle Unknown Class (11th Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_unknown_class(predictions, probabilities, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Detect potential unknown class based on prediction confidence\n",
    "    \n",
    "    Args:\n",
    "        predictions: Predicted class labels\n",
    "        probabilities: Prediction probabilities for each class\n",
    "        threshold: Confidence threshold below which we classify as unknown\n",
    "    \n",
    "    Returns:\n",
    "        Modified predictions with unknown class\n",
    "    \"\"\"\n",
    "    # Get maximum probability for each prediction\n",
    "    max_probabilities = np.max(probabilities, axis=1)\n",
    "    \n",
    "    # Create a copy of predictions\n",
    "    modified_predictions = predictions.copy()\n",
    "    \n",
    "    # Mark low-confidence predictions as unknown class (assuming class 10 is unknown)\n",
    "    unknown_mask = max_probabilities < threshold\n",
    "    modified_predictions[unknown_mask] = 10  # Unknown class\n",
    "    \n",
    "    print(f\"Detected {np.sum(unknown_mask)} potential unknown class samples\")\n",
    "    print(f\"Percentage of unknown samples: {np.sum(unknown_mask)/len(predictions)*100:.2f}%\")\n",
    "    \n",
    "    return modified_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect unknown class samples\n",
    "final_predictions = detect_unknown_class(test_predictions, test_probabilities, threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 16: Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(dataset, predictions, output_file=\"submissionOOD.csv\", unknown_label=\"unknown\"):\n",
    "    submission_data = []\n",
    "\n",
    "    # Get reverse class mapping\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        image_path = dataset.image_paths[i]\n",
    "        true_label_idx = dataset.labels[i]\n",
    "\n",
    "        pred_class_id = predictions[i]\n",
    "\n",
    "        # If prediction is an unknown class index (e.g., 99), name it \"unknown\"\n",
    "        if pred_class_id in idx_to_class:\n",
    "            pred_class_name = idx_to_class[pred_class_id]\n",
    "        else:\n",
    "            pred_class_name = unknown_label\n",
    "\n",
    "        submission_data.append({\n",
    "            \"Path\": image_path,\n",
    "            \"TrueLabel\": idx_to_class[true_label_idx],\n",
    "            \"PredictedLabel\": pred_class_name,\n",
    "            \"PredictedClassId\": pred_class_id\n",
    "        })\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved submission to {output_file}\")\n",
    "\n",
    "    return submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = create_submission(test_dataset, final_predictions, output_file=\"submissionOOD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 17: Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'num_classes': num_classes,\n",
    "    'f1_score': f1_macro,\n",
    "    'history': history\n",
    "}, 'art_style_classifierOOD.pth')\n",
    "\n",
    "print(\"Model saved as 'art_style_classifierOOD.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the model\n",
    "def load_model(model_path, num_classes):\n",
    "    \"\"\"\n",
    "    Load a saved model\n",
    "    \"\"\"\n",
    "    model = ArtStyleClassifier(num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Best F1 score: {checkpoint['f1_score']:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example of loading the model\n",
    "# loaded_model = load_model('art_style_classifier.pth', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 18: Advanced Features (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ensemble example\n",
    "def create_ensemble_predictions(models, test_loader, device):\n",
    "    \"\"\"\n",
    "    Create ensemble predictions from multiple models\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                model_predictions.append(probabilities.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(np.concatenate(model_predictions))\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_predictions = np.mean(all_predictions, axis=0)\n",
    "    final_predictions = np.argmax(ensemble_predictions, axis=1)\n",
    "    \n",
    "    return final_predictions, ensemble_predictions\n",
    "\n",
    "# Gradient-weighted Class Activation Mapping (Grad-CAM)\n",
    "def generate_gradcam(model, image, class_idx, target_layer):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for model interpretability\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    features = []\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(output)\n",
    "    \n",
    "    handle = target_layer.register_forward_hook(hook_fn)\n",
    "    \n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = model(image)\n",
    "    \n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    output[0, class_idx].backward()\n",
    "    \n",
    "    # Get gradients and features\n",
    "    gradients = target_layer.weight.grad\n",
    "    activations = features[0]\n",
    "    \n",
    "    # Generate heatmap\n",
    "    weights = torch.mean(gradients, dim=(2, 3))\n",
    "    heatmap = torch.zeros(activations.shape[2:]).to(device)\n",
    "    \n",
    "    for i in range(weights.shape[1]):\n",
    "        heatmap += weights[0, i] * activations[0, i]\n",
    "    \n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap = heatmap / torch.max(heatmap)\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    return heatmap.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 19: Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to load model instead of training\n",
    "USE_SAVED_MODEL = True  # Set to True if you want to load a saved model\n",
    "\n",
    "# Updated load_model function to return history\n",
    "def load_model_with_history(model_path, num_classes):\n",
    "    \"\"\"\n",
    "    Load a saved model along with its training history\n",
    "    \"\"\"\n",
    "    model = ArtStyleClassifier(num_classes)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    # Extract history if available\n",
    "    history = checkpoint.get('history', None)\n",
    "    f1_score = checkpoint.get('f1_score', 0.0)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Best F1 score: {f1_score:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if USE_SAVED_MODEL:\n",
    "    # Load the saved model\n",
    "    loaded_model, history = load_model_with_history('art_style_classifierOOD.pth', num_classes)\n",
    "    model = loaded_model\n",
    "    \n",
    "    # If no history available, skip visualization or create dummy\n",
    "    if history is None:\n",
    "        print(\"No training history available - skipping training plots\")\n",
    "        # You can either skip plot_training_history() or create dummy data\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'val_f1_macro': [],\n",
    "            'val_f1_weighted': []\n",
    "        }\n",
    "else:\n",
    "    # Use the freshly trained model (existing code continues)\n",
    "    history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "    \n",
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions, test_probabilities = predict_test_data(model, test_loader, device)\n",
    "# Continue with evaluation\n",
    "f1_macro, f1_weighted, val_probabilities = evaluate_model(model, val_loader, device)\n",
    "# Detect unknown class samples\n",
    "final_predictions = detect_unknown_class(test_predictions, test_probabilities, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"Final F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"Number of test predictions: {len(final_predictions)}\")\n",
    "print(f\"Model saved: art_style_classifier.pth\")\n",
    "print(f\"Submission file: submission.csv\")\n",
    "print(f\"Device used: {device}\")\n",
    "print(f\"Total training time: {len(history['train_loss'])} epochs\")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"- Base model: ResNet50 (pre-trained)\")\n",
    "print(f\"- Number of classes: {num_classes}\")\n",
    "print(f\"- Total parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\nNext steps to improve performance:\")\n",
    "print(\"1. Try different architectures (EfficientNet, Vision Transformer)\")\n",
    "print(\"2. Experiment with different data augmentation techniques\")\n",
    "print(\"3. Implement test-time augmentation (TTA)\")\n",
    "print(\"4. Use model ensembling\")\n",
    "print(\"5. Fine-tune hyperparameters\")\n",
    "print(\"6. Implement advanced loss functions (Focal Loss, Label Smoothing)\")\n",
    "print(\"7. Use cross-validation for more robust evaluation\")\n",
    "print(\"8. Analyze model predictions with Grad-CAM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
